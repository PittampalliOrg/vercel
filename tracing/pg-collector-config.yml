receivers:
  filelog:
    include_file_path: true
    include:
      - ./logs/*.json
    operators:
      - id: container-parser
        type: container

  postgresql:
    collection_interval: 2m0s
    databases:
      - postgres
    endpoint: localhost:5432
    password: postgres
    tls:
      insecure: true
    transport: tcp
    username: postgres
  sqlquery/postgres:
    driver: postgres
    # Adjust host/port/db/user/password as needed for your environment:
    datasource: "host=db port=5432 user=postgres password=postgres dbname=postgres sslmode=disable"
    # OPTIONAL: if you want to store the last tracking column across restarts,
    # set `storage: your_storage_extension_name_here`
    queries:
      - sql: "SELECT id, chat_id, created_at
          FROM message
          WHERE created_at > $1
          ORDER BY created_at ASC"
        tracking_column: created_at
        # Choose a start time well before your earliest data, e.g. Jan 1, 2024:
        tracking_start_value: "2024-01-01 00:00:00"

        logs:
          - body_column: content
            # Put columns you want as log attributes:
            attribute_columns: ["id", "chat_id", "created_at"]
            # If you also want the actual timestamp included, you could add "created_at" above.

exporters:
  otlp:
    endpoint: "otel-collector:4317"
    tls:
      insecure: true
  debug:
    verbosity: detailed
  otlp/metrics:
    endpoint: "data-prepper:21891"
    tls:
      insecure: true
      insecure_skip_verify: true
  prometheusremotewrite:
    endpoint: "http://prometheus:9090/api/v1/write"
    resource_to_telemetry_conversion:
      enabled: true
    timeout: 60s
    tls:
      insecure_skip_verify: true
  # azuredataexplorer:
  #   cluster_uri: "https://azdexplorer.northcentralus.kusto.windows.net"
  #   application_id: "11d953d9-3ed7-4f8c-92d0-a6c311dba3f1"
  #   application_key: "${env:AZURE_STORAGE_EXPLORER_KEY}"
  #   tenant_id: "0c4da9c5-40ea-4e7d-9c7a-e7308d4f8e38"
  #   db_name: "db"
  #   metrics_table_name: "metrics"
  #   logs_table_name: "logs"
  #   traces_table_name: "traces"
  #   ingestion_type : "managed"



processors:
  transform:
    error_mode: ignore
    log_statements:
      - context: resource
        statements:
          - set(attributes["log.group.name"], "pgvector")
      - context: log
        statements:
          - set(severity_text, attributes["error_severity"])

  resourcedetection:
    detectors:
      - system
    system:
      hostname_sources:
        - os
  batch:

service:
  pipelines:
    logs:
      receivers: [filelog] # your logs receivers
      processors: [resourcedetection, transform]
      exporters: [otlp, debug]
    metrics:
      receivers: [postgresql]
      processors: [batch]
      exporters: [otlp, debug]
