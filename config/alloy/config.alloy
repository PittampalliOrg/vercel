livedebugging {
  enabled = true
}

otelcol.receiver.filelog "postgres_logs" {
  include = ["/var/lib/docker/containers/*/*.log"]
  operators = [
    {
      // Router to identify Docker JSON logs
      type = "router",
      id = "get-format",
      routes = [
        {
          output = "extract_docker_metadata",
          expr = "body matches \"^\\\\{\"",
        },
      ],
    },
    {
      // Extract Docker metadata
      type = "json_parser",
      id = "extract_docker_metadata",
      output = "filter_postgres",
    },
    {
      // Filter to only include PostgreSQL container logs
      type = "filter",
      id = "filter_postgres",
      expr = "attributes.container_name matches \".*postgres.*\"",
      output = "extract_postgres_log",
    },
    {
      // Parse PostgreSQL logs
      type = "json_parser",
      id = "extract_postgres_log",
      field = "attributes.log",
      output = "add_resource_attributes",
    },
    {
      // Add resource attributes for correlation
      type = "add",
      id = "add_resource_attributes",
      field = "resource.attributes.service.name",
      value = "postgresql",
    },
  ]
  output {
    logs = [otelcol.exporter.debug.default.input]
  }
}

// Make sure this component exists
otelcol.exporter.debug "default" {}


otelcol.receiver.otlp "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.receiver.otlp/
    
    // configures the default grpc endpoint "0.0.0.0:4317"
    grpc { }
    // configures the default http/protobuf endpoint "0.0.0.0:4318"
    http {
        cors {
            allowed_origins = ["http://localhost", "https://*"]
            allowed_headers = ["Content-Type", "X-Api-Key", "X-Faro-Session-Id"]
            max_age         = 7200
        }
        include_metadata = true
    }
    
  output {
    metrics = [otelcol.exporter.debug.traefik_metrics.input, otelcol.processor.resourcedetection.default.input]
    traces  = [otelcol.exporter.debug.traefik_traces.input, otelcol.processor.resourcedetection.default.input]
    logs    = [otelcol.processor.resourcedetection.default.input]
  }
}

otelcol.processor.resourcedetection "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.resourcedetection/
    detectors = ["env", "system"]
    
    system {
        hostname_sources = ["os"]
    }
    
    output {
        metrics = [otelcol.processor.transform.drop_unneeded_resource_attributes.input]
        logs    = [otelcol.processor.transform.drop_unneeded_resource_attributes.input]
        traces  = [otelcol.processor.transform.drop_unneeded_resource_attributes.input]
    }
}

otelcol.processor.transform "drop_unneeded_resource_attributes" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
    error_mode = "ignore"
    
    trace_statements {
        context    = "resource"
        statements = [
            "delete_key(attributes, \"k8s.pod.start_time\")",
            "delete_key(attributes, \"os.description\")",
            "delete_key(attributes, \"os.type\")",
            "delete_key(attributes, \"process.command_args\")",
            "delete_key(attributes, \"process.executable.path\")",
            "delete_key(attributes, \"process.pid\")",
            "delete_key(attributes, \"process.runtime.description\")",
            "delete_key(attributes, \"process.runtime.name\")",
            "delete_key(attributes, \"process.runtime.version\")",
        ]
    }
    
    metric_statements {
        context    = "resource"
        statements = [
            "delete_key(attributes, \"k8s.pod.start_time\")",
            "delete_key(attributes, \"os.description\")",
            "delete_key(attributes, \"os.type\")",
            "delete_key(attributes, \"process.command_args\")",
            "delete_key(attributes, \"process.executable.path\")",
            "delete_key(attributes, \"process.pid\")",
            "delete_key(attributes, \"process.runtime.description\")",
            "delete_key(attributes, \"process.runtime.name\")",
            "delete_key(attributes, \"process.runtime.version\")",
        ]
    }
    
    log_statements {
        context    = "resource"
        statements = [
            "delete_key(attributes, \"k8s.pod.start_time\")",
            "delete_key(attributes, \"os.description\")",
            "delete_key(attributes, \"os.type\")",
            "delete_key(attributes, \"process.command_args\")",
            "delete_key(attributes, \"process.executable.path\")",
            "delete_key(attributes, \"process.pid\")",
            "delete_key(attributes, \"process.runtime.description\")",
            "delete_key(attributes, \"process.runtime.name\")",
            "delete_key(attributes, \"process.runtime.version\")",
        ]
    }
    
    output {
        metrics = [otelcol.processor.transform.add_resource_attributes_as_metric_attributes.input]
        logs    = [otelcol.processor.batch.default.input]
        traces  = [
            otelcol.connector.servicegraph.default.input,
            otelcol.connector.spanmetrics.default.input,
            otelcol.processor.probabilistic_sampler.default.input,
            otelcol.connector.host_info.default.input,
        ]
    }
}

// Added servicegraph connector for better trace visualization
otelcol.connector.servicegraph "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.connector.servicegraph/
    dimensions = [
        "service.namespace",
        "service.version",
        "deployment.environment",
        "k8s.cluster.name",
        "k8s.namespace.name",
        "cloud.region",
        "cloud.availability_zone",
    ]
    latency_histogram_buckets = ["0.005s", "0.01s", "0.025s", "0.05s", "0.075s", "0.1s", "0.25s", "0.5s", "0.75s", "1s", "2.5s", "5s", "7.5s", "10s"]
    
    store {
        ttl = "2s"
    }
    
    output {
        metrics = [otelcol.processor.batch.default.input]
    }
}

// Added spanmetrics connector for better trace metrics
otelcol.connector.spanmetrics "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.connector.spanmetrics/
    dimension {
        name = "service.namespace"
    }
    
    dimension {
        name = "service.version"
    }
    
    dimension {
        name = "deployment.environment"
    }
    
    dimension {
        name = "k8s.cluster.name"
    }
    
    dimension {
        name = "k8s.namespace.name"
    }
    
    dimension {
        name = "cloud.region"
    }
    
    dimension {
        name = "cloud.availability_zone"
    }
    
    histogram {
        explicit {
            buckets = ["0.005s", "0.01s", "0.025s", "0.05s", "0.075s", "0.1s", "0.25s", "0.5s", "0.75s", "1s", "2.5s", "5s", "7.5s", "10s"]
        }
        unit = "s"
    }
    
    output {
        metrics = [otelcol.processor.batch.default.input]
    }
}

// Added probabilistic sampler to reduce trace volume
otelcol.processor.probabilistic_sampler "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.probabilistic_sampler/
    sampling_percentage = 10 // Keep 10% of traces
    
    output {
        traces = [otelcol.processor.batch.default.input]
    }
}

otelcol.connector.host_info "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.connector.host_info/
    host_identifiers = ["host.name"]
    
    output {
        metrics = [otelcol.processor.batch.default.input]
    }
}

otelcol.processor.transform "add_resource_attributes_as_metric_attributes" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
    error_mode = "ignore"
    
    metric_statements {
        context    = "datapoint"
        statements = [
            "set(attributes[\"deployment.environment\"], resource.attributes[\"deployment.environment\"])",
            "set(attributes[\"service.version\"], resource.attributes[\"service.version\"])",
        ]
    }
    
    output {
        metrics = [otelcol.processor.batch.default.input]
    }
}

otelcol.processor.batch "default" {
    // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.batch/
    output {
        metrics = [otelcol.exporter.otlphttp.default_mimir.input]
        logs    = [otelcol.exporter.otlphttp.default_loki.input]
        traces  = [otelcol.exporter.otlp.default_tempo.input]
    }
}

otelcol.exporter.otlphttp "default_mimir" {
    client {
        endpoint                = "http://mimir:9009/otlp"
        max_idle_conns_per_host = 0
        max_conns_per_host      = 0
        http2_ping_timeout      = "0s"
    }
}

otelcol.exporter.otlphttp "default_loki" {
    client {
        endpoint                = "http://loki:3100/otlp"
        max_idle_conns_per_host = 0
        max_conns_per_host      = 0
        http2_ping_timeout      = "0s"
    }
}

otelcol.exporter.otlp "default_tempo" {
    client {
        endpoint = "tempo:4317"
        
        tls {
            insecure = true
        }
    }
}

// Process discovery for profiling
discovery.process "all" { }

discovery.relabel "alloy" {
    targets = discovery.process.all.targets
    // Filter needed processes
    rule {
        source_labels = ["__meta_process_exe"]
        regex         = ".*/alloy"
        action        = "keep"
    }
    
    // provide arbitrary service_name label, otherwise it will be "unspecified"
    rule {
        source_labels = ["__meta_process_exe"]
        target_label  = "service_name"
        regex         = ".*/alloy"
        action        = "replace"
        replacement   = "ebpf/local/alloy"
    }
}

// Pyroscope configuration - either enable both components or comment out both
// pyroscope.ebpf "instance" {
//     forward_to = [pyroscope.write.endpoint.receiver]
//     targets    = discovery.relabel.alloy.output
// }

// pyroscope.write "endpoint" {
//     endpoint {
//         url = "http://pyroscope:4040"
//         // url = "<Grafana Cloud URL>",
//         // basic_auth {
//         //  username = "<Grafana Cloud User>",
//         //  password = "<Grafana Cloud Password>",
//         // }
//     }
// }

// PostgreSQL table size metrics collection
prometheus.exporter.postgres "postgres_table_size" {
    data_source_names = ["postgresql://postgres:postgres@db:5432/postgres?sslmode=disable"]
    custom_queries_config_path = "/etc/alloy/pg_table_size-details.yaml"
}

prometheus.exporter.postgres "postgres_queries" {
  data_source_names = ["postgresql://postgres:postgres@db:5432/postgres?sslmode=disable"]
  custom_queries_config_path = "/etc/alloy/queries-pg_stat.yaml"
  
  disable_settings_metrics = true
}

prometheus.scrape "postgres_query_metrics" {
  targets = prometheus.exporter.postgres.postgres_queries.targets
  forward_to = [prometheus.relabel.truncate_query_labels.receiver]
}

// Then, apply relabeling to truncate long query labels
prometheus.relabel "truncate_query_labels" {
  rule {
    source_labels = ["query"]
    regex = "(.{1,1000}).*"  // Truncate to 1000 chars
    target_label = "query"
    replacement = "$1..."
  }
  
  forward_to = [otelcol.receiver.prometheus.postgres.receiver]
}
// Scrape PostgreSQL table size metrics
prometheus.scrape "postgres_table_size_metrics" {
    targets    = prometheus.exporter.postgres.postgres_table_size.targets
    forward_to = [otelcol.receiver.prometheus.postgres.receiver]
}

// Convert Prometheus metrics to OTLP format
otelcol.receiver.prometheus "postgres" {
    output {
        metrics = [otelcol.processor.batch.default.input]
    }
}

// PostgreSQL log collection
local.file_match "logs_integrations_postgres_exporter" {
    path_targets = [{
        __address__ = "localhost",
        __path__    = "/logs/postgresql-*.log", // Matches your log_filename pattern
        instance    = constants.hostname,
        job         = "integrations/postgres_exporter",
    }]
}

loki.source.file "logs_integrations_postgres_exporter" {
    targets    = local.file_match.logs_integrations_postgres_exporter.targets
    forward_to = [otelcol.receiver.loki.postgres_logs.receiver]
}

otelcol.receiver.loki "postgres_logs" {
    output {
        logs = [otelcol.processor.batch.default.input]
    }
}

discovery.relabel "metrics_integrations_integrations_traefik" {
  targets = [{
    __address__ = "traefik:8080",  // Adjust to your Traefik metrics endpoint
  }]

  rule {
    target_label = "instance"
    replacement  = constants.hostname
  }
}

prometheus.scrape "metrics_integrations_integrations_traefik" {
  targets    = discovery.relabel.metrics_integrations_integrations_traefik.output
  forward_to = [prometheus.remote_write.default.receiver]  // Or use otelcol.receiver.prometheus
  job_name   = "integrations/traefik"
}

// Option 1: If you want to use Prometheus format
prometheus.remote_write "default" {
  endpoint {
    url = "http://mimir:9009/api/prom/push"  // Adjust to your endpoint
  }
}
otelcol.exporter.debug "traefik_metrics" {
  verbosity = "detailed"
}

otelcol.exporter.debug "traefik_traces" {
  verbosity = "detailed"
}