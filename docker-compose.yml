x-default-logging: &logging
  driver: "json-file"
  options:
    max-size: "5m"
    max-file: "2"
    tag: "{{.Name}}"

networks:
  default:
    name: opentelemetry
    driver: bridge
    external: true
    attachable: true

volumes:
  postgres-data:
  opensearch-data:
  prometheus_data:


services:
  frontend:
    container_name: frontend
    image: next-js
    ports:
      - "3000:3000"
    volumes:
      # - /var/run/docker.sock:/var/run/docker-host.sock 
      - .:/workspace:cached
    entrypoint: /usr/local/share/docker-init.sh
    command: sleep infinity 

  frontend_dapr:
    container_name: frontend_dapr
    image: "daprio/daprd"
    command: ["./daprd", "-app-id", "frontend", "-app-port", "3000", "-resources-path", "/dapr", "-config", "/dapr/config.yaml", "-enable-api-logging", "-log-level", "debug", "--app-channel-address", "frontend"]
    volumes:
      - "./dapr:/dapr"

    depends_on:
      - frontend
      - db    

  natural-language:
    container_name: natural-language
    image: next-js
    ports:
      - "4000:3000"
    volumes:
      # - /var/run/docker.sock:/var/run/docker-host.sock 
      - ../natural-language-postgres:/workspace:cached
    entrypoint: /usr/local/share/docker-init.sh
    command: sleep infinity 

  natural-language_dapr:
    container_name: natural-language_dapr
    image: "daprio/daprd"
    command: ["./daprd", "-app-id", "natural-language", "-app-port", "4000", "-resources-path", "/dapr", "-config", "/dapr/config.yaml", "-enable-api-logging", "-log-level", "debug", "--app-channel-address", "natural-language"]
    volumes:
      - "./dapr:/dapr"

    depends_on:
      - natural-language
      - db    

  # api:
  #   container_name: api
  #   image: next-js
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker-host.sock 
  #     - ../mastering-observability-with-opentelemetry-4515650:/workspace:cached    

  # api_dapr:
  #   container_name: api_dapr
  #   image: "daprio/daprd"

  #   command: ["./daprd", "--app-id", "api", "-app-port", "8080", "--resources-path", "/dapr", "--config", "/dapr/config.yaml", "--enable-api-logging", "--log-level", "debug", "--app-channel-address", "api"]
  #   volumes:
  #     - "./dapr:/dapr"

  #   depends_on:
  #     - api
  #     - db    

  dab:
    container_name: dab
    image: mcr.microsoft.com/azure-databases/data-api-builder
    volumes:
      - type: bind
        source: ./dab-config.json
        target: /App/dab-config.json
        read_only: true
    ports:
      - "5000:5000"
      
    environment:
      SQL_CONN_STRING: "Host=db;Port=5432;Database=postgres;User ID=postgres;Password=postgres;"
      DAB_ENVIRONMENT: Development

    command: ["dab", "start", "-c", "./App/dab-config.json"]
    depends_on:
      - db
    

  dab_dapr:
    container_name: dab_dapr
    image: "daprio/daprd:edge"
    command: ["./daprd", "-app-id", "dab", "-app-port", "5000", "-resources-path", "/dapr", "-config", "/dapr/config.yaml", "-enable-api-logging", "--log-level", "debug", "--app-channel-address", "dab"]
    volumes:
      - "./dapr:/dapr"

    depends_on:
      - dab    

  db:
    container_name: db
    image: pgvector/pgvector:pg17
    restart: unless-stopped
    volumes:
      - postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_USER: postgres
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"      
    

  # ********************
  # Telemetry Components
  # ********************
  # Jaeger
  jaeger:
    image: ${JAEGERTRACING_IMAGE}
    container_name: jaeger
    command:
      - "--memory.max-traces=5000"
      - "--query.base-path=/jaeger/ui"
      - "--prometheus.server-url=http://${PROMETHEUS_ADDR}"
      - "--prometheus.query.normalize-calls=true"
      - "--prometheus.query.normalize-duration=true"
    deploy:
      resources:
        limits:
          memory: 400M
    restart: unless-stopped
    ports:
      - "${JAEGER_PORT}:${JAEGER_PORT}"         # Jaeger UI
      - "${OTEL_COLLECTOR_PORT_GRPC}"
    environment:
      - METRICS_STORAGE_TYPE=prometheus
    logging: *logging

  # Grafana
  grafana:
    image: ${GRAFANA_IMAGE}
    container_name: grafana
    deploy:
      resources:
        limits:
          memory: 120M
    restart: unless-stopped
    environment:
      - "GF_INSTALL_PLUGINS=grafana-opensearch-datasource"
    volumes:
      - ./src/grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./src/grafana/provisioning/:/etc/grafana/provisioning/
    ports:
      - "3005:${GRAFANA_PORT}"
    logging: *logging

  # OpenTelemetry Collector
  otel-collector:
    image: ${COLLECTOR_CONTRIB_IMAGE}
    container_name: otel-collector
    deploy:
      resources:
        limits:
          memory: 200M
    restart: unless-stopped
    command: [ "--config=/etc/otelcol-config.yml", "--config=/etc/otelcol-config-extras.yml" ]
    user: 0:0
    volumes:
      - ${HOST_FILESYSTEM}:/hostfs:ro
      - ${DOCKER_SOCK}:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./tracing/otel-collector-config.yml:/etc/otelcol-config.yml
      - ./tracing/otelcol-config-extras.yml:/etc/otelcol-config-extras.yml
    ports:
      - "${OTEL_COLLECTOR_PORT_GRPC}"
      - "${OTEL_COLLECTOR_PORT_HTTP}"
      - "13133:13133" # health check port
      - "9464" # Prometheus exporter
      - "8889" # metrics endpoint
    depends_on:
      jaeger:
        condition: service_started
      opensearch:
        condition: service_healthy
    logging: *logging
    environment:
      - ENVOY_PORT
      - HOST_FILESYSTEM=""
      - OTEL_COLLECTOR_HOST
      - OTEL_COLLECTOR_PORT_GRPC
      - OTEL_COLLECTOR_PORT_HTTP
      - TRACELOOP_API_KEY

  prometheus:
    image: quay.io/prometheus/prometheus:v2.47.2
    container_name: prometheus
    command:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=1h
      - --config.file=/etc/prometheus/prometheus-config.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --enable-feature=exemplar-storage
      - --enable-feature=otlp-write-receiver
      - --web.enable-remote-write-receiver
    volumes:
      - prometheus_data:/usr/share/prometheus/data
      - ./src/prometheus/prometheus-config.yaml:/etc/prometheus/prometheus-config.yaml
    deploy:
      resources:
        limits:
          memory: 500M
    ports:
      - "${PROMETHEUS_SERVICE_PORT}:${PROMETHEUS_SERVICE_PORT}"
    logging: *logging

  # OpenSearch
  opensearch:
    image: opensearchproject/opensearch:latest
    container_name: opensearch
    deploy:
      resources:
        limits:
          memory: 1.1G
    restart: unless-stopped
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch # Name the node that will run in this container
      - discovery.seed_hosts=opensearch # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch # Nodes eligibile to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which installs demo certificates and security configurations to OpenSearch
      - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - opensearch-data:/usr/share/opensearch/data # Creates volume called opensearch-data1 and mounts it to the container
    ports:
      - "9200:9200"
    healthcheck:
      test: curl -s http://localhost:9200/_cluster/health | grep -E '"status":"(green|yellow)"'
      start_period: 10s
      interval: 5s
      timeout: 10s
      retries: 10
    logging: *logging
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest # Make sure the version of opensearch-dashboards matches the version of opensearch installed on other nodes
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    volumes:
      - ./src/dashboards/config/opensearch_dashboards.yml:/usr/share/opensearch-dashboards/config/opensearch_dashboards.yml
    environment:
      - 'OPENSEARCH_HOSTS=["http://opensearch:9200"]'
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true" # disables security dashboards plugin in OpenSearch Dashboards
  data-prepper:
    platform: linux/amd64
    image: opensearchproject/data-prepper:latest
    container_name: dataprepper
    volumes:
      - /data/service-map/
      - ./src/dataprepper/templates/ss4o_metrics.json:/usr/share/data-prepper/templates/ss4o_metrics.json
      - ./src/dataprepper/templates/ss4o_logs.json:/usr/share/data-prepper/templates/ss4o_logs.json
      - ./src/dataprepper/templates/ss4o_traces.json:/usr/share/data-prepper/templates/ss4o_traces.json
      - ./src/dataprepper/pipelines.yaml:/usr/share/data-prepper/pipelines/pipelines.yaml
      - ./src/dataprepper/data-prepper-config.yaml:/usr/share/data-prepper/config/data-prepper-config.yaml
    ports:
      - "21890:21890"
      - "21891:21891"
      - "21892:21892"
    expose:
      - "21890"
      - "21891"
      - "21892"
    logging: *logging
    depends_on:
      - opensearch-dashboards